{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from model.networks import Generator, Discriminator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1f7ad",
   "metadata": {},
   "source": [
    "### Loading pretrained checkpoints for DeepFill and CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained GAN model for inpainting\n",
    "path_to_generator_ckpt = \"pretrained_inpaint/states.pth\"\n",
    "path_to_CNN_ckpt = \"pretrained_GNN/checkpoints\"\n",
    "use_cuda_if_available = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() \n",
    "                             and use_cuda_if_available else 'cpu')\n",
    "generator_inpaint = Generator(cnum_in=5, cnum=48, return_flow=True).to(device)\n",
    "\n",
    "# generator_state_dict = torch.load('pretrained/states_tf_places2.pth')['G']\n",
    "generator_inpaint_state_dict = torch.load(path_to_generator_ckpt)['G']\n",
    "generator_inpaint.load_state_dict(generator_inpaint_state_dict)\n",
    "\n",
    "# Load pretrained GAN model for inverse design from field to geometry\n",
    "\n",
    "forward_CNN = tf.keras.models.load_model(path_to_CNN_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6533d1ea",
   "metadata": {},
   "source": [
    "### Functions needed for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae78876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_to_rgb(pt): return pt[0].cpu().permute(1, 2, 0)*0.5 + 0.5\n",
    "def predict_inpaint(image, mask, generator_inpaint):\n",
    "    \"\"\"\n",
    "    The input are Pillow image objects\n",
    "    \"\"\"\n",
    "    image_org = T.ToTensor()(image)\n",
    "    mask = T.ToTensor()(mask)\n",
    "\n",
    "    _, h, w = image_org.shape\n",
    "    grid = 8\n",
    "\n",
    "    image = image_org[:3, :h//grid*grid, :w//grid*grid].unsqueeze(0)\n",
    "    mask = mask[0:1, :h//grid*grid, :w//grid*grid].unsqueeze(0)\n",
    "\n",
    "    print(f\"Shape of image: {image.shape}\")\n",
    "\n",
    "    image = (image*2 - 1.).to(device)  # map image values to [-1, 1] range\n",
    "    mask = (mask > 0.).to(dtype=torch.float32, device=device)  # 1.: masked 0.: unmasked\n",
    "\n",
    "    image_masked = image * (1.-mask)  # mask image\n",
    "\n",
    "    ones_x = torch.ones_like(image_masked)[:, 0:1, :, :]\n",
    "    x = torch.cat([image_masked, ones_x, ones_x*mask], dim=1)  # concatenate channels\n",
    "    with torch.no_grad():\n",
    "        x_stage1, x_stage2, offset_flow = generator_inpaint(x, mask)\n",
    "\n",
    "    image_inpainted = image_masked * (1.-mask) + x_stage2 * mask\n",
    "    return pt_to_rgb(image_masked).numpy(), pt_to_rgb(image_inpainted).numpy()                                                                                                                  \n",
    "\n",
    "\n",
    "def predict_geo(image):\n",
    "    \"\"\"\n",
    "    The input are numpy arrays\n",
    "    \"\"\"\n",
    "    IMG_WIDTH = 256\n",
    "    IMG_HEIGHT = 256\n",
    "    num_block = 8\n",
    "    interval_x = IMG_WIDTH / num_block\n",
    "    interval_y = IMG_HEIGHT / num_block\n",
    "    seq = np.squeeze((forward_CNN.predict(np.expand_dims(image, axis=0)) > 0.5).astype(\"int\"))\n",
    "    img = np.zeros((IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    for i in range(IMG_WIDTH):\n",
    "        for j in range(IMG_HEIGHT):\n",
    "            idx_x = i // interval_x\n",
    "            if idx_x > 3:\n",
    "                idx_x = 7 - idx_x\n",
    "            idx_y = (IMG_HEIGHT - j - 1) // interval_y\n",
    "            order = int(idx_x * num_block + idx_y)\n",
    "            if i < 3 or i > IMG_WIDTH - 4 or j < 3 or j > IMG_HEIGHT - 4:\n",
    "                img[j][i][0] = 0\n",
    "                img[j][i][1] = 0\n",
    "                img[j][i][2] = 0 \n",
    "            else:\n",
    "                img[j][i][0] = 1\n",
    "                img[j][i][1] = seq[order]\n",
    "                img[j][i][2] = img[j][i][1]\n",
    "        \n",
    "    \n",
    "    return seq, img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897de423",
   "metadata": {},
   "source": [
    "### Testing field completion results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate results for all test data\n",
    "\n",
    "path_field_map = \"./predictions/field_maps/\"\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path_field_map)\n",
    "if not isExist:\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "    os.makedirs(path_field_map)\n",
    "\n",
    "for i in range(200):\n",
    "    image = Image.open(\"./datasets/S11_8/test/\" + str(i + 801) + \".jpg\") \n",
    "    bbox = random_bbox()\n",
    "    regular_mask = bbox2mask(bbox)\n",
    "    irregular_mask = brush_stroke_mask()\n",
    "    mask = torch.logical_or(irregular_mask, regular_mask).to(torch.float32)\n",
    "    empty = np.zeros((1, 4, 256, 256))\n",
    "    mask = mask + empty\n",
    "    mask = mask[0].permute(1, 2, 0) * 255\n",
    "    mask = np.squeeze(mask.to(device='cpu', dtype=torch.uint8).numpy())\n",
    "    mask = Image.fromarray(mask.astype(np.uint8))\n",
    "    img_masked, img_field_pred = predict_inpaint(image, mask, generator_inpaint)\n",
    "    img_object = Image.fromarray(np.uint8(img_field_pred * 255))\n",
    "    img_object.save(path_field_map + str(i + 1) + \".jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5471ac",
   "metadata": {},
   "source": [
    "### Using CNN model for inverse translation from field back to structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate inverse results\n",
    "\n",
    "path_geo = \"./predictions/geos/\"\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path_geo)\n",
    "if not isExist:\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "    os.makedirs(path_geo)\n",
    "    \n",
    "for i in range(200):\n",
    "    img_field_pred = Image.open(path_field_map + str(i + 1) + \".jpg\")\n",
    "    img_field_pred = np.array(img_field_pred) / 255\n",
    "    seq, img_geo_pred = predict_geo(img_field_pred)\n",
    "    img_object = Image.fromarray(np.uint8(img_geo_pred * 255))\n",
    "    img_object.save(path_geo + str(i + 1) + \".jpg\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1110",
   "language": "python",
   "name": "pytorch-1110"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
